{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Factorization Machine\n",
    "###  Intro\n",
    "* FM model is very efficient in fitting dataset with sparse matrix.\n",
    "* It was applied in Kaggle competition for Click-Through-Rate(CTR) prediction, and achieved excellent results.\n",
    "* FM model has the following strengths:\n",
    "    * Works with very sparse data where SVMs fail.\n",
    "    * By introducing interaction terms to linear models,it generates higher dimensional features and improves accuracy compared to simple logistic models\n",
    "    * FM has linear complexity,and do not reply on support vectors like SVMs\n",
    "* Other applications:\n",
    "    * Regression\n",
    "    * Binary Classification\n",
    "    * Ranking\n",
    "    \n",
    "### Mathematics\n",
    "* target function with interaction terms\n",
    "\n",
    "<img src=\"files/fm_formula.png\">\n",
    "<img src=\"files/fm_vector.png\">\n",
    "* derivation for linear complexity\n",
    "<img src=\"files/fm_inter.png\">\n",
    "\n",
    "Loss functions\n",
    "* regression(MSE)\n",
    "<img src=\"files/fm_rg_func.png\">\n",
    "<img src=\"files/fm_rg_func2.png\">\n",
    "\n",
    "* classification(Logit loss)\n",
    "<img src=\"files/fm_lg_func.png\">\n",
    "<img src=\"files/fm_lg_func2.png\">\n",
    "<img src=\"files/fm_lg_func3.png\">\n",
    "\n",
    "* Gradient for classificaiton with sigmoid loss\n",
    "<img src=\"files/fm_loss_func.png\">\n",
    "\n",
    "* The algo goes\n",
    "<img src=\"files/fm_sgd.png\">\n",
    "\n",
    "#### References\n",
    "* Rendle, Factorization Machines.\n",
    "* Factorization Machines with libFM\n",
    "* FM:http://www.cs.cmu.edu/~wcohen/10-605/2015-guest-lecture/FM.pdf \n",
    "* A quick summary on FM and FFM from meituan:https://tech.meituan.com/2016/03/03/deep-understanding-of-ffm-principles-and-practices.html\n",
    "* Kaggle competition:https://www.kaggle.com/c/avazu-ctr-prediction/discussion/10729#latest-236361\n",
    "* https://www.cnblogs.com/wkang/p/9588360.html#4267887\n",
    "* https://blog.csdn.net/google19890102/article/details/45532745"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an implementation example for FM in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "from numpy import *\n",
    "from random import normalvariate # random number from normal distribution\n",
    "from datetime import datetime\n",
    "from sklearn import datasets\n",
    "\n",
    "def sigmoid(x): return 1.0/(1+exp(-x))\n",
    "\n",
    "class FactorizationMachine():\n",
    "    \"\"\"\n",
    "    example to fit factorization machine using stochastic gradient descent \n",
    "    \"\"\"\n",
    "    def __init__(self,k=5,alpha=0.01,max_iter=10,verbose=True):\n",
    "        self.max_iter = max_iter\n",
    "        self.k = k  # dimension(columns) for factor v\n",
    "        self.alpha = alpha # learning rate\n",
    "        self._verbose = verbose\n",
    "    \n",
    "    def predict_proba(self,test_X):\n",
    "        y_prob = []\n",
    "        # for easy calc\n",
    "        v = self.v\n",
    "        w_0 = self.w_0\n",
    "        w = self.w\n",
    "        for row_i in range(test_X.shape[0]):\n",
    "            inter1 = test_X[row_i] * v\n",
    "            inter2 = multiply(test_X[row_i],test_X[row_i]) * multiply(v,v)\n",
    "            interaction = sum(multiply(inter1,inter1) - inter2)/2.\n",
    "            p = w_0 + test_X[row_i] * w + interaction\n",
    "            prob = sigmoid(p[0,0])\n",
    "            y_prob.append(prob)\n",
    "        return y_prob\n",
    "    \n",
    "    def predict(self,test_X):\n",
    "        y_pred = []\n",
    "        # for easy calc\n",
    "        v = self.v\n",
    "        w_0 = self.w_0\n",
    "        w = self.w\n",
    "        for row_i in range(test_X.shape[0]):\n",
    "            inter1 = mat(test_X[row_i]) * v    # x_i * v_i\n",
    "            inter2 = mat(multiply(test_X[row_i],test_X[row_i])) * multiply(v,v)\n",
    "            interaction = sum(multiply(inter1,inter1) - inter2)/2.\n",
    "            p = w_0 + test_X[row_i] * w + interaction\n",
    "            prob = sigmoid(p[0,0])\n",
    "            y_pred.append(1 if prob>.5 else 0)\n",
    "        return y_pred\n",
    "        \n",
    "    def _SGDSolver(self):\n",
    "        # for easy calc\n",
    "        v = self.v\n",
    "        w_0 = self.w_0\n",
    "        w = self.w\n",
    "        \n",
    "        for itr in range(self.max_iter):\n",
    "            if self._verbose:\n",
    "                print('iter  number: ',itr)\n",
    "            \n",
    "            for row_i in range(self.nrows):  # n samples\n",
    "                inter1 = self.train_X[row_i] * v                \n",
    "                inter2 = multiply(self.train_X[row_i],self.train_X[row_i]) * multiply(v,v)\n",
    "                interaction = sum(multiply(inter1,inter1) - inter2)/2.\n",
    "                p = w_0 + transpose(self.train_X[row_i]) * w + interaction\n",
    "\n",
    "                loss = sigmoid(self.train_y[row_i]*p[0,0]) - 1 # derivative  of sigmoid \n",
    "                if self._verbose:\n",
    "                    print('sample no: ',row_i,'pred: ',p,' loss: ', self.alpha * loss * self.train_y[row_i])\n",
    "                    \n",
    "                w_0 = w_0 - self.alpha * loss * self.train_y[row_i]\n",
    "                \n",
    "                # update w\n",
    "                for i in range(self.ncols):\n",
    "                    if self.train_X[row_i,i] != 0:\n",
    "                        w[i,0] = w[i,0] -self.alpha * loss * self.train_y[row_i] * self.train_X[row_i,i]\n",
    "                \n",
    "                # update v\n",
    "                for i in range(self.ncols):\n",
    "                    for j in range(self.k):\n",
    "                        v[i,j] = v[i,j] - self.alpha * loss * self.train_y[row_i] * (self.train_X[row_i,i] * inter1[0,j] - v[i,j] * self.train_X[row_i,i] * self.train_X[row_i,i])\n",
    "    \n",
    "        # assign results\n",
    "        self.v = v\n",
    "        self.w_0 = w_0\n",
    "        self.w = w\n",
    "    \n",
    "    def fit(self,train_X,train_y):\n",
    "        self.train_X = train_X\n",
    "        self.train_y = train_y\n",
    "        self.nrows,self.ncols = shape(train_X)\n",
    "        # initialize factors\n",
    "        self.w_0 = 0\n",
    "        self.w = mat(zeros((self.ncols,1)))\n",
    "        self.v = mat(normalvariate(0,.2) * ones((self.ncols,self.k)))\n",
    "        if self._verbose:\n",
    "            print(self.train_X.shape,',',self.w.shape,',',self.v.shape)\n",
    "        # run solver algo\n",
    "        self._SGDSolver() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification,make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "X,y = make_blobs(n_samples=1000,random_state=1,n_features=10)\n",
    "train_X,test_X,train_y,test_y = train_test_split(X,y,test_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = FactorizationMachine(max_iter=100,k=8,verbose=False)\n",
    "fm.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fm.predict(train_X)\n",
    "(train_y==y_pred).astype(int).sum()/len(train_y)\n",
    "y_pred = fm.predict(test_X)\n",
    "(test_y==y_pred).astype(int).sum()/len(test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
